<h1 align="center">EXPRESSANDO - TDoC 2021</h1>
<p align="center">
<img src="https://user-images.githubusercontent.com/76585827/137585523-2ff41a7e-3859-44e9-85ae-d0014a4fc661.png" style="height:auto; width:50%"></img>
</p>

<h1 align="center">DAY 6</h1>

# Demonstration of Data-Collection and Introduction to TensorFlow 

In this session, we are going to have a demonstartion on how to collect data with increased precision. This is a vital step, as it governs the future processes which are required in making the model. So let us begin.

## What is a 'Dataset'? 

A Dataset as **a collection of data that is treated as a single unit by a computer**. This means that a dataset contains a lot of separate pieces of data/images but can be used to train an algorithm with the goal of finding predictable patterns inside the whole dataset. The datasets contains individual classes, which are representation of the single unit. Here. we will be having two **customised** datasets - **test** and **train**. Each dataset here contains: 0, 1, 2, 3, 4 and 5, which are the classes, or the single units.

Datasets are of three types: 
* **Training Dataset** - This dataset which contains the necessary data with which the model is to be trained. This dataset contains the maximum amount of data, and it is primarily used by the machine for comparison. 
* **Validation Dataset** - This dataset checks for the validation of the input in accordance with the training dataset. It is a subset of the training dataset. It eliminates unnecessary inputs, and increase the speed of operation.
* **Test Dataset** - This dataset is used for testing the models, and determine the accuracy and losses which are incurred while training the machine. This is very much important, as it serves as a test set for the training data, and the user can verify the results.

Now let us 
## Step 1:
